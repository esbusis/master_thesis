{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import babel\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "from prody import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134a196",
   "metadata": {},
   "source": [
    "# 1- CLEANING INHIBITORS \n",
    "\n",
    "(USED R FOR THIS, SEE THE FILE cleaning_inhibitors.R to find the codes)\n",
    "\n",
    "removed mutants, mutations and duplicates.\n",
    "\n",
    "Input = inhibitors_from_chembl.csv\n",
    "Output = Unique_Chembl.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffdb90",
   "metadata": {},
   "source": [
    "# 2- Getting Ligand SMILES ID's\n",
    "\n",
    "INPUT = Unique_Chembl.csv\n",
    "\n",
    "OUTPUT = multiple smiles files, including all the ligands in Unique_Chembl.csv \n",
    "\n",
    "You can find already created files in /Important_Files/Ligand_smiles folder.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl = pd.read_csv(\"Unique_Chembl.csv\")\n",
    "smilesids = chembl[\"Smiles\"]\n",
    "names = chembl[\"Molecule.ChEMBL.ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0431426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(smilesids)):                            \n",
    "    file_name ='%s.smiles'% names[i]\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(smilesids[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20edee",
   "metadata": {},
   "source": [
    "# 3- PROTEIN AND LIGAND PREPARE FOR DOCKING \n",
    "\n",
    "(USED GOOGLE COLAB AND BASH FOR THIS,CHECK OUT THE CODES IN Colab_Protein_Ligand_prepare_for_docking.ipynb)\n",
    "\n",
    "preparing ligands\n",
    "\n",
    "INPUT = Ligand smiles files inside Ligand_smiles folder\n",
    "\n",
    "OUTPUT = Ligand mol2 and pdbqt files in Ligands file\n",
    "\n",
    "preparing protein file\n",
    "\n",
    "INPUT = alpha_templated.pdb file in Protein folder\n",
    "\n",
    "OUTPUT = alpha_templated.pdbqt file in Protein folder\n",
    "\n",
    "preparing substrates\n",
    "\n",
    "INPUT = Substrate smiles files in Substrate folder\n",
    "\n",
    "OUTPUT = Substrate pdbqt files in Substrate folder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab95275",
   "metadata": {},
   "source": [
    "# 4- VINA DOCKING FUNCTION \n",
    "\n",
    "There are multiple docking runs executed for this project.\n",
    "\n",
    "1- Docking all ligands and substrates to a binding pocket that was suggested by EASYVS - \"\"-12.073,-0.049,5.027\". The resulting files can be found under \"Important Files/Docking Results/alpha_easyvs_pockets_run\". The folders are named based on the exhaustiveness level and/or the day docking runs started and vina results are named based on the CHEMBL ID's.\n",
    "\n",
    "INPUT: pdbqt files in Ligands, Substrates and Protein folder\n",
    "\n",
    "OUTPUT: vina results under Important Files/Docking Results/alpha_easyvs_pockets_run\n",
    "\n",
    "2- Docking all ligands and substrates to binding pockets generated by DogSiteScorer. The resulting files can be found under \"Important Files/Docking Results/alpha_DogSite_new_pockets_run\". The folders are named based on the pocket number (0 or 1) and the vina results are named based on the CHEMBL ID's.\n",
    "\n",
    "INPUT: pdbqt files in Ligands, Substrates and Protein folder\n",
    "\n",
    "OUTPUT: vina results under Important Files/Docking Results/alpha_DogSite_new_pockets_run\n",
    "\n",
    "3- Docking function is used to dock Ciprofloxacin to all binding pockets obtained for each conformation extracted from MD simulations. The new conformation files are under \"New_Conformations\" folder. The files are named based on the date of Dynamics simulation and the number of frame which the structure was obtained. The results of this docking can be found under /Important Files/Docking Results/Ciprofloxacin_with_Coord_from_MD. The file coordinates.xlsx includes the necessary information for XYZ coordinates of each conformation and highly important for docking function.\n",
    "\n",
    "INPUT: Ciprofloxacin pdbqt as substrate, coordinates.xlsx file for extracting coordinates of all conformations and norA structure pdb files under New_Conformations folder.\n",
    "\n",
    "OUTPUT: vina results under Important Files/Docking Results/Ciprofloxacin_with_Coord_from_MD\n",
    "\n",
    "4- Docking all ligands to all new nora conformations extracted from MD. Ligands are in Ligands folder, protein structures are in New Conformations folder. XYZ coordinates and radius of the binding pockets are in coordinates.xlsx which is critical for the docking process. Output files were under /Important_Files/Docking_results/All_Ligands_All_Conformations_Run. There were 267 ligands but at the end we could only get 194 molecules (due to time limit we stopped at this number), which reduced to 178 then 96 after filtering out the results. Folders are named based on the ligand name. and results are named based on the conformation and the pocket name.\n",
    "\n",
    "INPUT: Ligands folder, New Conformations folder and coordinates.xlsx file.\n",
    "\n",
    "OUTPUT: All_Ligands_All_Conformations_Run folder under /Important_Files/Docking_Results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088aec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKING FUNCTION FOR FIRST ROUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "alias vina /Users/esbusis/autodock_vina_1_1_2_mac_catalina_64bit/bin/vina #change this to exe directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a is the center_x\n",
    "# b is the center_y\n",
    "# c is the center_z\n",
    "# d is the size_x\n",
    "# e is the size_y\n",
    "#f is the size_z\n",
    "\n",
    "\n",
    "def docking(protein,ligand,a,b,c,d,e,g,outfolder):\n",
    "    \n",
    "    matches = re.search(\".(CHEMBL\\d+).\", ligand)\n",
    "    ligname = matches.groups()[0]\n",
    "    \n",
    "    with open(\"config_singledock.txt\",\"w\") as f:\n",
    "      f.write(\"#CONFIGURATION FILE (options not used are commented) \\n\")\n",
    "      f.write(\"\\n\")\n",
    "      f.write(\"#INPUT OPTIONS \\n\")\n",
    "      f.write(\"receptor = %s \\n\" % str(protein))\n",
    "      f.write(\"ligand = %s \\n\" % str(ligand))\n",
    "      f.write(\"#flex = [flexible residues in receptor in pdbqt format] \\n\")\n",
    "      f.write(\"#SEARCH SPACE CONFIGURATIONS \\n\")\n",
    "      f.write(\"#Center of the box (values bxi, byi and bzi) \\n\")\n",
    "#CHANGE THE FOLLOWING DATA WITH YOUR BOX CENTER COORDINATES  \n",
    "      f.write(\"center_x = %d  \\n\" % float(a))\n",
    "      f.write(\"center_y = %d  \\n\" % float(b))\n",
    "      f.write(\"center_z = %d  \\n\" % float(c))\n",
    "#CHANGE THE FOLLOWING DATA WITH YOUR BOX DIMENSIONS\n",
    "      f.write(\"#Size of the box (values bxf, byf and bzf) \\n\")\n",
    "      f.write(\"size_x = %d  \\n\" % float(d))\n",
    "      f.write(\"size_y = %d  \\n\" % float(e))\n",
    "      f.write(\"size_z = %d  \\n\" % float(g))\n",
    "      f.write(\"#OUTPUT OPTIONS \\n\")\n",
    "      f.write(\"out = %s \\n\" % (outfolder + \"/\" + str(ligname)+ \"_docked.pdbqt\"))\n",
    "      f.write(\"log = %s \\n\" % (outfolder + \"/\" + str(ligname)+ \"_docked.log\"))\n",
    "      f.write(\"\\n\")\n",
    "      f.write(\"#OTHER OPTIONS \\n\")\n",
    "      f.write(\"#cpu =  \\n\")\n",
    "      f.write(\"exhaustiveness = 512\")\n",
    "      f.write(\"#num_modes = \\n\")\n",
    "      f.write(\"#energy_range = \\n\")\n",
    "      f.write(\"#seed = \")\n",
    "\n",
    "\n",
    "#Executing AutoDock Vina with our configuration file\n",
    "    %vina --config config_singledock.txt\n",
    "    \n",
    "\n",
    "    \n",
    "    #!obabel -ipdbqt lig.pdbqt -opdb -O lig_dock.pdb -m\n",
    "    \n",
    "    #return lig_dock.pdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ef078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKING FOR FIRST ROUND\n",
    "\n",
    "# DOCKING LIGANDS to a certain XYZ coordinate obtained from EASYVS\n",
    "\n",
    "# Make sure the change directories of ligands, protein or substrates based on your project.\n",
    "\n",
    "# The resulting files can be found under \"Important Files/Docking Results/alpha_easyvs_pockets_run/ligands\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "nora = \"/Protein/alpha_templated.pdbqt\"\n",
    "ligands = glob.glob(\"/Ligands/*pdbqt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"08_12_2021_Vina_Run\")\n",
    "\n",
    "for lig in ligands:\n",
    "    docking(nora, lig,-12.073,-0.049,5.027,20,20,20,\"08_12_2021_Vina_Run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKING FOR FIRST ROUND\n",
    "\n",
    "# DOCKING SUBSTRATES to a certain XYZ coordinate obtained from EASYVS\n",
    "\n",
    "# Make sure the change directories of ligands, protein or substrates based on your project.\n",
    "\n",
    "# The resulting files can be found under \"Important Files/Docking Results/alpha_easyvs_pockets_run/substrates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nora = \"/Protein/alpha_templated.pdbqt\"\n",
    "substrates = glob.glob(\"/Substrates/*pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e336bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"Substrates_Run_512\")\n",
    "\n",
    "for lig in substrates:\n",
    "    docking(nora, lig,-12.073,-0.049,5.027,20,20,20,\"Substrates_Run_512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKING FUNCTION FOR SECOND ROUND\n",
    "\n",
    "# Make sure the change directories of ligands, protein or substrates based on your project.\n",
    "\n",
    "# The resulting files can be found under \"Important Files/Docking Results/alpha_DogSite_new_pockets_run/ligands\"\n",
    "# and alpha_DogSite_new_pockets_run/substrates for the Substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57411b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nora = \"/Protein/alpha_templated.pdbqt\"\n",
    "ligands = glob.glob(\"/Ligands/*pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee76b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"27_02_2022_pocket_0_run_1\")\n",
    "\n",
    "for lig in ligands:\n",
    "    docking(nora, lig,-4.04,-0.11,-2.87,20,20,20,\"27_02_2022_pocket_0_run_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8645b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "nora = \"/Protein/alpha_templated.pdbqt\"\n",
    "ligands = glob.glob(\"/Ligands/*pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"27_02_2022_pocket_0_run_1\")\n",
    "\n",
    "for lig in ligands:\n",
    "    docking(nora, lig,-12.02,9.48,-0.80,20,20,20,\"27_02_2022_pocket_0_run_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKING FUNCTION FOR THIRD ROUND\n",
    "\n",
    "# Here it is important to set the directory for ciprofloxacin and conformation files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f1cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.read_excel(\"coordinates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = '/Substrates/CHEMBL8_ciprofloxin.pdbqt'\n",
    "os.mkdir(\"cipro_runs\")\n",
    "for i in range(len(coordinates)):\n",
    "    docking(coordinates[\"File Name\"][i],lig,coordinates[\"X Coordination\"][i],coordinates[\"Y Coordination\"][i],coordinates[\"Z Coordination\"][i],coordinates[\"Radius\"][i],coordinates[\"Radius\"][i],coordinates[\"Radius\"][i],\"cipro_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0005c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCKING FUNCTION FOR THE FOURTH ROUND\n",
    "\n",
    "# Again, change the coordinates if necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb914a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.read_excel(\"coordinates.xlsx\")\n",
    "ligands = glob.glob(\"Ligands/*pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab5ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lig in ligands:\n",
    "    matches = re.search(\".(CHEMBL\\d+).\", lig)\n",
    "    ligname = matches.groups()[0]\n",
    "    a = \"Run/\" + ligname + \"_run_1\"\n",
    "    os.mkdir(a)\n",
    "    for i in range(len(coordinates)):\n",
    "        docking(\"New_Coordinates/\" + coordinates[\"File Name\"][i],lig,coordinates[\"X Coordination\"][i],coordinates[\"Y Coordination\"][i],coordinates[\"Z Coordination\"][i],coordinates[\"Radius\"][i],coordinates[\"Radius\"][i],coordinates[\"Radius\"][i],a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16797b06",
   "metadata": {},
   "source": [
    "# 5- PARSING THE RESULTS OF DOCKING\n",
    "\n",
    "The codes have multiple layers. \n",
    "\n",
    "1- Getting the metadata: The codes in here are used to obtain important information from Unique_Chembl.csv, because the original dataset is crowded and includes information that might not be usefull. These extracted values then saved to a csv named \"metadata.csv\".\n",
    "\n",
    "INPUT: Unique_Chembl.csv\n",
    "\n",
    "OUTPUT: metadata.csv\n",
    "\n",
    "2- Extracting vina results: Extracting Binding affinity, RMSD scores from log files of ligand vina results obtained in the first round of docking and some important info as the Run, Ligand to create a new dataframe. This dataframe will be combined with metadata, hence we will obtain a dataframe containing metadata and vina results for each chemical.\n",
    "\n",
    "For ligands in the first round\n",
    "\n",
    "INPUT: Log files of docking results, under /Important_Files/Docking_Results/alpha_easyvs_pockets_run/ligands\n",
    "\n",
    "OUTPUT: masterdf_alpha_easyvs_coordinates.csv\n",
    "\n",
    "For substrates in the first round\n",
    "\n",
    "INPUT: /Important_Files/Docking_Results/alpha_easyvs_pockets_run/substrates\n",
    "\n",
    "OUTPUT: substrate_runs_alpha_easyvs.csv\n",
    "\n",
    "For Ciprofloxacin in the third round\n",
    "\n",
    "INPUT: /Important_Files/Docking_Results/Ciprofloxacin_with_Coord_from_MD\n",
    "\n",
    "OUTPUT: cipro_new_conformations.csv\n",
    "\n",
    "! The results for the second round docking has not been added here, because we did not use it in the study.\n",
    "\n",
    "For all results in the fourth round:\n",
    "\n",
    "INPUT: /Important_Files/Docking_Results/All_Ligands_All_Conformations_Run\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ea64c",
   "metadata": {},
   "source": [
    "## 5.1- Getting the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d017faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"Unique_Chembl.csv\")\n",
    "metadata2 = metadata[[\"Molecule.ChEMBL.ID\",\"AlogP\",\"Standard.Type\",\"Standard.Relation\",\"Standard.Value\",\"Comment\",\"Assay.Description\",\"Assay.ChEMBL.ID\"]]\n",
    "substrates = []\n",
    "for i,j in enumerate(metadata2[\"Assay.Description\"]):\n",
    "    substrates.append([])\n",
    "    if \"ethidium bromide\" in j:\n",
    "        substrates[i].append(\"Ethidium Bromide\")\n",
    "    elif \"ciprofloxacin\" in j:\n",
    "        substrates[i].append(\"Ciprofloxacin\")\n",
    "    elif \"EtBr\" in j:\n",
    "        substrates[i].append(\"Ethidium Bromide\")\n",
    "    elif \"Mg2+\" in j:\n",
    "        substrates[i].append(\"Hoechst 33342\")\n",
    "    elif \"Berberine\" in j:\n",
    "        substrates[i].append(\"Berberine\")\n",
    "    else:\n",
    "        substrates[i].append(\"None\")\n",
    "metadata2[\"Substrates\"] = substrates\n",
    "metadata2 = metadata2.rename(columns={\"Molecule.ChEMBL.ID\":\"Ligand\"})\n",
    "\n",
    "metadata2.to_csv(\"metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92f073",
   "metadata": {},
   "source": [
    "## 5.2- Extracting Vina Results\n",
    "\n",
    "Here, the results are extracted for Ligands docked in the first round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac19169",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = glob.glob(\"/Important_Files/Docking_Results/alpha_easyvs_pockets_run/ligands/*Vina_Run*/*log\")\n",
    "\n",
    "df3 = pd.DataFrame(columns=[\"Run\",\"Ligand\",'Pose','BA','RMSD','RMSD_2'])\n",
    "\n",
    "for i in log_files:\n",
    "        \n",
    "    with open(i) as f:\n",
    "        a = f.readlines()\n",
    "    \n",
    "    we = a[25:34]\n",
    "    tt = []\n",
    "    for k in we:\n",
    "        r = k.split(\" \")\n",
    "        o = [float(el.rstrip(\"\\n\")) for el in r if el != \"\"]\n",
    "        tt.append(o)\n",
    "\n",
    "    er = i.split(\"/\")\n",
    "    ligname= er[9].rstrip(\"_docked.log\")\n",
    "    filename= er[8]\n",
    "\n",
    "        \n",
    "    df2 = pd.DataFrame(tt, columns=['Pose','BA','RMSD','RMSD_2'])\n",
    "    df2['Pose','BA','RMSD','RMSD_2'] = tt\n",
    "    df2[\"Ligand\"] = ligname\n",
    "    df2[\"Run\"] = filename\n",
    "    df2 = df2[[\"Run\",\"Ligand\",\"Pose\",\"BA\",\"RMSD\",\"RMSD_2\"]]\n",
    "    \n",
    "    df3 = df3.append(df2)\n",
    "    \n",
    "#df3.to_csv(\"df3.csv\")\n",
    "unique_runs = np.unique(df3[\"Run\"].values)\n",
    "unique_ligands = np.unique(df3[\"Ligand\"].values)\n",
    "df3 = df3.reset_index()\n",
    "df3 = df3.drop(\"index\", axis = 1)\n",
    "\n",
    "for i in range(len(unique_runs)):\n",
    "    Run = unique_runs[i]\n",
    "    for j in range(len(unique_ligands)):\n",
    "        Ligand = unique_ligands[j]\n",
    "        \n",
    "        df4 = df3[(df3[\"Run\"] == Run) & (df3[\"Ligand\"] == Ligand)]\n",
    "        \n",
    "        #print(df4)\n",
    "        \n",
    "        ind = df3[(df3[\"Run\"] == Run) & (df3[\"Ligand\"] == Ligand)].index\n",
    "        \n",
    "        #print(ind)\n",
    "        \n",
    "        std_of_ba = np.std(df4[\"BA\"].values)\n",
    "        \n",
    "        df3.loc[ind, \"Std_BA\"] = std_of_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf = pd.merge(df3,metadata2, on= \"Ligand\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f11ff7",
   "metadata": {},
   "source": [
    "Here, the results are extracted for Substrates docked in the first round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a610fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For substrates\n",
    "\n",
    "substrates_files = glob.glob(\"/Important_Files/Docking_Results/alpha_easyvs_pockets_run/substrates/*Substrates_Run*/*log\")\n",
    "\n",
    "df5 = pd.DataFrame(columns=[\"Run\",\"Ligand\",'Pose','BA','RMSD','RMSD_2'])\n",
    "\n",
    "for i in substrates_files:\n",
    "        \n",
    "    with open(i) as f:\n",
    "        a = f.readlines()\n",
    "    \n",
    "    we = a[25:26]\n",
    "    tt = []\n",
    "    for k in we:\n",
    "        r = k.split(\" \")\n",
    "        o = [float(el.rstrip(\"\\n\")) for el in r if el != \"\"]\n",
    "        tt.append(o)\n",
    "\n",
    "    er = i.split(\"/\")\n",
    "    ligname= er[9].rstrip(\"_docked.log\")\n",
    "    filename= er[8]\n",
    "\n",
    "        \n",
    "    df2 = pd.DataFrame(tt, columns=['Pose','BA','RMSD','RMSD_2'])\n",
    "    df2['Pose','BA','RMSD','RMSD_2'] = tt\n",
    "    df2[\"Ligand\"] = ligname\n",
    "    df2[\"Run\"] = filename\n",
    "    df2 = df2[[\"Run\",\"Ligand\",\"Pose\",\"BA\",\"RMSD\",\"RMSD_2\"]]\n",
    "    \n",
    "    df5 = df5.append(df2)\n",
    "    \n",
    "df5.to_csv(\"substrate_runs_alpha_easyvs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96513bc",
   "metadata": {},
   "source": [
    "Here, the results are extracted for Ciprofloxacin docked in the third round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for alpha new pocket runs only pose 1 is collected\n",
    "# change only file location inside glob.glob and the name of the output file\n",
    "\n",
    "substrates_files = glob.glob(\"/Important_Files/Docking_Results/Ciprofloxacin_with_Coord_from_MD/*log\")\n",
    "\n",
    "df5 = pd.DataFrame(columns=[\"Run\",\"Ligand\",'Pose','BA','RMSD','RMSD_2'])\n",
    "\n",
    "for i in substrates_files:\n",
    "        \n",
    "    with open(i) as f:\n",
    "        a = f.readlines()\n",
    "    \n",
    "    we = a[25:26]\n",
    "    tt = []\n",
    "    for k in we:\n",
    "        r = k.split(\" \")\n",
    "        o = [float(el.rstrip(\"\\n\")) for el in r if el != \"\"]\n",
    "        tt.append(o)\n",
    "\n",
    "    er = i.split(\"/\")\n",
    "    ligname= er[7].rstrip(\"_docked.log\")\n",
    "    filename= er[6]\n",
    "\n",
    "        \n",
    "    df2 = pd.DataFrame(tt, columns=['Pose','BA','RMSD','RMSD_2'])\n",
    "    df2['Pose','BA','RMSD','RMSD_2'] = tt\n",
    "    df2[\"Ligand\"] = ligname\n",
    "    df2[\"Run\"] = filename\n",
    "    df2 = df2[[\"Run\",\"Ligand\",\"Pose\",\"BA\",\"RMSD\",\"RMSD_2\"]]\n",
    "    \n",
    "    df5 = df5.append(df2)\n",
    "    \n",
    "df5.to_csv(\"cipro_new_conformations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e78c8",
   "metadata": {},
   "source": [
    "Here, the results are extracted for fourth round. Not used in the final version but codes could come handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = glob.glob(\"/Important_Files/Docking_Results/All_Ligands_All_Conformations_Run/*_run_*/*log\")\n",
    "\n",
    "df3 = pd.DataFrame(columns=[\"Run\",\"Ligand\",'Pose','BA','RMSD','RMSD_2'])\n",
    "\n",
    "for i in log_files:\n",
    "        \n",
    "    with open(i) as f:\n",
    "        a = f.readlines()\n",
    "    \n",
    "    we = a[25:26]\n",
    "    tt = []\n",
    "    for k in we:\n",
    "        r = k.split(\" \")\n",
    "        o = [float(el.rstrip(\"\\n\")) for el in r if el != \"\"]\n",
    "        tt.append(o)\n",
    "\n",
    "    er = i.split(\"\\\\\")\n",
    "    ligname= er[2].rstrip(\"_docked.log\")\n",
    "    filename= er[1]\n",
    "\n",
    "        \n",
    "    df2 = pd.DataFrame(tt, columns=['Pose','BA','RMSD','RMSD_2'])\n",
    "    df2['Pose','BA','RMSD','RMSD_2'] = tt\n",
    "    df2[\"Ligand\"] = ligname\n",
    "    df2[\"Run\"] = filename\n",
    "    df2 = df2[[\"Run\",\"Ligand\",\"Pose\",\"BA\",\"RMSD\",\"RMSD_2\"]]\n",
    "    \n",
    "    df3 = df3.append(df2)\n",
    "\n",
    "# Adding Standard deviation of BA\n",
    "\n",
    "#df3.to_csv(\"df3.csv\")\n",
    "unique_runs = np.unique(df3[\"Run\"].values)\n",
    "unique_ligands = np.unique(df3[\"Ligand\"].values)\n",
    "df3 = df3.reset_index()\n",
    "df3 = df3.drop(\"index\", axis = 1)\n",
    "\n",
    "for i in range(len(unique_runs)):\n",
    "    Run = unique_runs[i]\n",
    "    for j in range(len(unique_ligands)):\n",
    "        Ligand = unique_ligands[j]\n",
    "        \n",
    "        df4 = df3[(df3[\"Run\"] == Run) & (df3[\"Ligand\"] == Ligand)]\n",
    "        \n",
    "        #print(df4)\n",
    "        \n",
    "        ind = df3[(df3[\"Run\"] == Run) & (df3[\"Ligand\"] == Ligand)].index\n",
    "        \n",
    "        #print(ind)\n",
    "        \n",
    "        std_of_ba = np.std(df4[\"BA\"].values)\n",
    "        \n",
    "        df3.loc[ind, \"Std_BA\"] = std_of_ba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af8490",
   "metadata": {},
   "source": [
    "# 6- BINDING SITE ANALYSYS\n",
    "\n",
    "\n",
    "MAIN PURPOSES:\n",
    "\n",
    "1- Get the first pose in ligand pdbqt files.\n",
    "\n",
    "2- Convert these pdbqt files to pdb files using babel (need to be installed by sudo apt)\n",
    "\n",
    "3- Combine new conformation pdb files with the ligand pdb files.\n",
    "\n",
    "4- Use plip and get amino acid residues that are on the binding site for each docking results.\n",
    "\n",
    "5- Parse xml files generated by plip analysis.\n",
    "\n",
    "\n",
    "To re-accomplish these steps, the ligand docking results stored under All_Ligands_All_Conformations_Run can be used, with conformation files stored under New_Conformations. Here, you can find all the generated files under /Important_Files/PLIP_Results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca6916",
   "metadata": {},
   "source": [
    "## 6.1- Getting the POSE 1 from output of vina - pdbqt file.\n",
    "\n",
    "Here, the aim is to get only POSE 1 from docking results. The pdbqt files are parsed and new pdbqt files are generated including only pose_1 results.\n",
    "\n",
    "Here we copied the docking results under Important_Files/Docking_Results/All_Ligands_All_Conformations_Run to PLIP_Results/Run_194 to save the files in another folder, in case we lose it during this new analysis\n",
    "\n",
    "\n",
    "INPUT: All ligand pdbqt files in PLIP_Results/PLIP_Ligands\n",
    "\n",
    "OUTPUT: _pose_1.pdbqt files within same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_1(input_file, output_file):\n",
    "    \n",
    "    with open(input_file,\"r\") as task:\n",
    "        with open(output_file,\"w\") as output:\n",
    "            \n",
    "            for line in task:\n",
    "                output.write(line)\n",
    "                    \n",
    "                if \"ENDMDL\" in line:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52691eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"/Important_Files/PLIP_Results/Run_194/*run*/*pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "    pose_1(i,\"{0}_pose_1.pdbqt\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6970da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_files = glob.glob(\"/Important_Files/PLIP_Results/Run_194/*run*/*pose_1.pdbqt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5aded",
   "metadata": {},
   "source": [
    "## 6.2- Preparing pdb files from pdbqt files by writing the commands to an sh file \n",
    "\n",
    "Remember, babel should be installed. But you can find bash files in the folder.\n",
    "\n",
    "INPUT: _pose_1.pdbqt files in PLIP_Results/Ligands folder\n",
    "\n",
    "OUTPUT: _pose_1.pdbqt.pdb files in the same folder.\n",
    "\n",
    "First the pdb files for ligands are generated.\n",
    "Then pdb files for new conformations are generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"prepare_ligand_pdb.sh\"\n",
    "with open(file_name, 'w') as f:\n",
    "    for i in pose_files:\n",
    "        f.write(\"babel -ipdbqt {0} -opdb {1}.pdb ; \\n\".format(i,i))\n",
    "\n",
    "\n",
    "!chmod +x prepare_ligand_pdb.sh\n",
    "!bash prepare_ligand_pdb.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate_files = glob.glob(\"/New_Conformations/*pdbqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3caa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"prepare_proteins_pdb.sh\"\n",
    "with open(file_name, 'w') as f:\n",
    "    for i in coordinate_files:\n",
    "        f.write(\"babel -ipdbqt {0} -opdb {1}.pdb ; \\n\".format(i,i))\n",
    "\n",
    "\n",
    "!chmod +x prepare_proteins_pdb.sh\n",
    "!bash prepare_proteins_pdb.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e008b",
   "metadata": {},
   "source": [
    "## 6.3- Combining PDB files of ligands and corresponding conformations.\n",
    "\n",
    "This is done because PLIP requires a PDB file combining protein and ligand PDB files.\n",
    "\n",
    "First we created a dataframe that contains ligand pdb files with corresponding protein pdb file.\n",
    "\n",
    "Then we combined them by creating a function and using the function on all files.\n",
    "\n",
    "INPUT: All protein pdb's, all ligand _pose_1.pdbqt.pdb's\n",
    "\n",
    "OUTPUT: Combined pdb files. These files named based on the conformation, binding pocket on the conformation, ligand name and at the and there is a _combined.pdb tag. These files are available under PLIP_Results/Ligands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447e193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_files = glob.glob(\"/New_Conformations/*pdb\")\n",
    "ligand_pose1_files = glob.glob(\"/Important_Files/PLIP_Results/Run_194/*run*/*pose_1.pdbqt.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a df that contains ligand pdb files with corresponding protein pdb file\n",
    "\n",
    "oo = []\n",
    "chembl = []\n",
    "\n",
    "for i in ligand_pose1_files:\n",
    "    a = i.split(\"/\")\n",
    "    vr = re.sub(\"_P_.*_docked.pdbqt_pose_1.pdbqt.pdb\",\"\", a[2])\n",
    "    tr = vr.replace(\".pdbqt\", \".pdbqt.pdb\")\n",
    "    rt = \"new_coord/\" +tr\n",
    "    \n",
    "    oo.append(rt)    \n",
    "    er = a[1].replace(\"_run_1\",\"\")\n",
    "    chembl.append(er)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"Ligands\"] = ligand_pose1_files\n",
    "df[\"Proteins\"] = oo\n",
    "df[\"Chembl\"] = chembl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combining_pdbs_only_atoms(file1,file2,file3):\n",
    "    \n",
    "    data = data2 = \"\"\n",
    "\n",
    "    with open(file1) as protein:\n",
    "        for line in protein:\n",
    "            if \"ATOM\" in line:\n",
    "                data += line\n",
    "    \n",
    "\n",
    "    with open(file2) as pose:\n",
    "        for line in pose:\n",
    "            if \"ATOM\" in line:\n",
    "                data2 += line\n",
    "    \n",
    "    data += \"\\n\"\n",
    "    data += data2\n",
    "\n",
    "    with open (file3, 'w') as fp:\n",
    "        fp.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caabe05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining two pdb files.\n",
    "\n",
    "for i in range(len(df)):\n",
    "    combining_pdbs_only_atoms(df[\"Proteins\"][i],df[\"Ligands\"][i],\"{0}_{1}_combined.pdb\".format(df[\"Ligands\"][i], df[\"Chembl\"][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7614af",
   "metadata": {},
   "source": [
    "## 6.4- Using PLIP\n",
    "\n",
    "Here, first we get all combined files, then copy all to a new file, then prepare a bash script for using PLIP.\n",
    "\n",
    "PLIP is also a CLI tool as babel and should be installed beforehand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8becbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_files = glob.glob(\"/Important_Files/PLIP_Results/Run_194/*run*/*combined.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d259d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in combined_files:\n",
    "    shutil.copy(file_name, \"/Important_Files/PLIP_Results/PLIP_Ligands/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_combined = glob.glob(\"/Important_Files/PLIP_Results/PLIP_Ligands/*pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ea241",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"plip_for_combined.sh\"\n",
    "with open(file_name, 'w') as f:\n",
    "    for i in list_of_combined:\n",
    "        f.write(\"plipcmd -f {0} -x -o {1}_plip \\n\".format(i,i))\n",
    "\n",
    "\n",
    "!chmod +x plip_for_combined.sh\n",
    "!bash plip_for_combined.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948a4cc",
   "metadata": {},
   "source": [
    "## 6.5- Parsing PLIP results\n",
    "\n",
    "PLIP generates XML files that includes binding sites for the given pdb files (that includes both protein and ligand).\n",
    "\n",
    "First we extract information from these XML files, then we merge these information with metadata and vina results to obtain a master dataframe, which will be used for further analyses.\n",
    "\n",
    "INPUT: PLIP xml results, Vina log files, metadata.csv\n",
    "\n",
    "OUTPUT: masterdf.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e083e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1# Parsing the xml report files\n",
    "\n",
    "all_reports = glob.glob(\"/Important_Files/PLIP_Results/PLIP_Ligands/*plip/*xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c863d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "df3 = pd.DataFrame(columns = [\"File Name\",\"Interaction\", \"Residue Number\", \"Residue Type\", \"Residue Chain\", \"Ligand\"])\n",
    "\n",
    "for i in all_reports:\n",
    "    \n",
    "    mytree = ET.parse(i)\n",
    "    myroot = mytree.getroot()\n",
    "\n",
    "    r = i.split(\"/\")\n",
    "    t = r[1].split(\"_\")\n",
    "    str_match = [x for x in t if re.search('CHEMBL', x)]\n",
    "    \n",
    "\n",
    "    file_name = []\n",
    "    interaction = []\n",
    "    residue_number = []\n",
    "    residue_type = []\n",
    "    residue_chain = []\n",
    "    ligand = []\n",
    "    chembl_name = []\n",
    "\n",
    "    for headers in myroot.findall(\"./bindingsite/interactions/\"):\n",
    "        for i in headers:\n",
    "            for j in i.findall(\"restype_lIg\"):\n",
    "                if j.text.find(\"UNL\") == 0 :\n",
    "\n",
    "                    df = pd.DataFrame()\n",
    "                    \n",
    "                    \n",
    "                    file_name.append(r[1])\n",
    "                    chembl_name.append(str_match[0])\n",
    "                    interaction.append(i.tag)\n",
    "                    residue_number.append(i.find(\"resnr\").text)\n",
    "                    residue_type.append(i.find(\"restype\").text)\n",
    "                    residue_chain.append(i.find(\"reschaIn\").text)\n",
    "                    ligand.append(j.text)\n",
    "\n",
    "    df = {\"File Name\": file_name, \"Ligand\": chembl_name ,\"Interaction\": interaction, \"Residue Number\": residue_number, \"Residue Type\" : residue_type, \"Residue Chain\" : residue_chain, \"Residue Ligand\" : ligand}\n",
    "\n",
    "    df2 = pd.DataFrame(df)\n",
    "    df3 = df3.append(df2)\n",
    "    \n",
    "df4 = df3.reset_index().drop(\"index\",axis = 1).sort_values(by = [\"Residue Number\", \"Residue Type\"])\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging aminoacid data with metadata\n",
    "\n",
    "metadata = pd.read_csv(\"metadata.csv\")\n",
    "proteins_and_metadata = pd.merge(df4,metadata, on = \"Ligand\").sort_values(by = [\"Residue Number\", \"Residue Type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c406ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = glob.glob(\"/Important_Files/PLIP_Results/Run_194/*run*/*log\")\n",
    "\n",
    "run_results = pd.DataFrame(columns=[\"Pocket\",\"Ligand\",'Pose','BA','RMSD','RMSD_2'])\n",
    "\n",
    "for i in log_files:\n",
    "        \n",
    "    with open(i) as f:\n",
    "        a = f.readlines()\n",
    "    \n",
    "    we = a[25:26]\n",
    "    tt = []\n",
    "    for k in we:\n",
    "        r = k.split(\" \")\n",
    "        o = [float(el.rstrip(\"\\n\")) for el in r if el != \"\"]\n",
    "        tt.append(o)\n",
    "\n",
    "    er = i.split(\"/\")\n",
    "    ligname= er[1].rstrip(\"_docked.log\")\n",
    "    filename= er[2]\n",
    "\n",
    "        \n",
    "    df2 = pd.DataFrame(tt, columns=['Pose','BA','RMSD','RMSD_2'])\n",
    "    df2['Pose','BA','RMSD','RMSD_2'] = tt\n",
    "    df2[\"Ligand\"] = ligname\n",
    "    df2[\"Pocket\"] = filename\n",
    "    df2 = df2[[\"Pocket\",\"Ligand\",\"Pose\",\"BA\",\"RMSD\",\"RMSD_2\"]]\n",
    "    \n",
    "    run_results = run_results.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2141183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the log file names -- will be appended to \"run_results\"\n",
    "\n",
    "log_file_cleaned = []\n",
    "\n",
    "a = run_results[\"Pocket\"].to_list()\n",
    "\n",
    "aa = run_results[\"Ligand\"].to_list()\n",
    "\n",
    "for i in range(len(run_results)):\n",
    "    \n",
    "\n",
    "    c = aa[i].split(\"_\")\n",
    "\n",
    "    chembl = c[0]\n",
    "\n",
    "    d = a[i].split(\"_\")\n",
    "\n",
    "    \n",
    "    if \"12\" in d:\n",
    "    \n",
    "        d.remove(\"coordinates.pdbqt\")\n",
    "        d.remove(\"docked.log\")\n",
    "        d.append(chembl)\n",
    "\n",
    "        t = \"_\".join(d)\n",
    "        log_file_cleaned.append(t)\n",
    "        \n",
    "        \n",
    "    elif \"09\" in d:\n",
    "    \n",
    "        d.remove(\"coordinates\")\n",
    "        d.remove(\"docked.log\")\n",
    "        d[2] = d[2].replace(\".pdbqt\",\"\")\n",
    "        d.append(chembl)\n",
    "        t = \"_\".join(d)\n",
    "        \n",
    "        log_file_cleaned.append(t)\n",
    "\n",
    "run_results[\"Coordinates\"] = log_file_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the protein file names -- will be appended to \"proteins_and_metadata\"\n",
    "\n",
    "proteins_and_metadata_file_name = proteins_and_metadata[\"File Name\"].to_list()\n",
    "\n",
    "protein_file_cleaned =[]\n",
    "\n",
    "for i in range(len(proteins_and_metadata)):\n",
    "\n",
    "    b = proteins_and_metadata_file_name[i].split(\"_\")\n",
    "\n",
    "    \n",
    "    if \"12\" in b:\n",
    "    \n",
    "        b.remove(\"coordinates.pdbqt\")\n",
    "        b.remove(\"docked.pdbqt\")\n",
    "        b.remove(\"1.pdbqt.pdb\")\n",
    "        b.remove(\"combined.pdb\")\n",
    "        b.remove(\"plip\")\n",
    "        b.remove(\"pose\")\n",
    "\n",
    "        t = \"_\".join(b)\n",
    "        \n",
    "        protein_file_cleaned.append(t)\n",
    "        \n",
    "    elif \"09\" in b:\n",
    "    \n",
    "        b.remove(\"coordinates\")\n",
    "        b.remove(\"docked.pdbqt\")\n",
    "        b.remove(\"1.pdbqt.pdb\")\n",
    "        b.remove(\"combined.pdb\")\n",
    "        b.remove(\"plip\")\n",
    "        b.remove(\"pose\")\n",
    "        b[2] = b[2].replace(\".pdbqt\",\"\")\n",
    "\n",
    "        t = \"_\".join(b)\n",
    "        \n",
    "        protein_file_cleaned.append(t)\n",
    "        \n",
    "proteins_and_metadata[\"Coordinates\"] = protein_file_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce364eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging aminoacid data with metadata\n",
    "\n",
    "masterdf = pd.merge(run_results,proteins_and_metadata, on = \"Coordinates\").sort_values(by = [\"Residue Number\", \"Residue Type\"])\n",
    "\n",
    "#masterdf.to_csv(\"masterdf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f703bc6f",
   "metadata": {},
   "source": [
    "# Cipro PLIP Results Parsing\n",
    "\n",
    "Parsing PLIP results for Ciprofloxacin.\n",
    "\n",
    "The same procedures applies for cipro, but it is simpler due to size of the data.\n",
    "\n",
    "INPUT: PLIP xml results for ciprofloxacin under cipro_combined.\n",
    "\n",
    "OUTPUT: cipro_binding_sites.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reports = glob.glob(\"/Important_Files/PLIP_Results/PLIP_Cipro/*plip/*xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652639f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "df9 = pd.DataFrame(columns = [\"File Name\",\"Interaction\", \"Residue Number\", \"Residue Type\", \"Residue Chain\", \"Ligand\"])\n",
    "\n",
    "for i in all_reports:\n",
    "    \n",
    "    mytree = ET.parse(i)\n",
    "    myroot = mytree.getroot()\n",
    "\n",
    "    r = i.split(\"/\")\n",
    "    t = r[1].split(\"_\")\n",
    "\n",
    "\n",
    "    file_name = []\n",
    "    interaction = []\n",
    "    residue_number = []\n",
    "    residue_type = []\n",
    "    residue_chain = []\n",
    "    ligand = []\n",
    "   \n",
    "\n",
    "    for headers in myroot.findall(\"./bindingsite/interactions/\"):\n",
    "        for i in headers:\n",
    "            for j in i.findall(\"restype_lIg\"):\n",
    "                if j.text.find(\"LIG\") == 0 :\n",
    "\n",
    "                    df7 = pd.DataFrame()\n",
    "                    \n",
    "                    \n",
    "                    file_name.append(r[1])\n",
    "                    interaction.append(i.tag)\n",
    "                    residue_number.append(i.find(\"resnr\").text)\n",
    "                    residue_type.append(i.find(\"restype\").text)\n",
    "                    residue_chain.append(i.find(\"reschaIn\").text)\n",
    "                    ligand.append(j.text)\n",
    "\n",
    "    df7 = {\"File Name\": file_name,\"Interaction\": interaction, \"Residue Number\": residue_number, \"Residue Type\" : residue_type, \"Residue Chain\" : residue_chain, \"Residue Ligand\" : ligand}\n",
    "\n",
    "    df8 = pd.DataFrame(df7)\n",
    "    df9 = df9.append(df8)\n",
    "    \n",
    "df10 = df9.reset_index().drop(\"index\",axis = 1).sort_values(by = [\"Residue Number\", \"Residue Type\"])\n",
    "\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56247e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.to_csv(\"cipro_binding_sites.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce8fe6",
   "metadata": {},
   "source": [
    "# Binding Site Analysis for Cipro\n",
    "\n",
    "INPUT: cipro_new_conformations.csv and cipro_binding_sites.csv\n",
    "\n",
    "OUTPUT: cipro_bs_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipro = pd.read_csv(\"cipro_new_conformations.csv\")\n",
    "cipro_binding_sites = pd.read_csv(\"cipro_binding_sites.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409759fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_and_metadata_file_name = cipro_binding_sites[\"File Name\"].to_list()\n",
    "\n",
    "protein_file_cleaned =[]\n",
    "\n",
    "for i in range(len(cipro_binding_sites)):\n",
    "\n",
    "    b = proteins_and_metadata_file_name[i].split(\"_\")\n",
    "\n",
    "\n",
    "    if \"12\" in b:\n",
    "\n",
    "        b.remove(\"coordinates.pdbqt\")\n",
    "        b.remove(\"docked.pdbqt\")\n",
    "        b.remove(\"1.pdbqt.pdb\")\n",
    "        b.remove(\"combined.pdb\")\n",
    "        b.remove(\"plip\")\n",
    "        b.remove(\"pose\")\n",
    "        b.remove(\"cipro\")\n",
    "\n",
    "        t = \"_\".join(b)\n",
    "\n",
    "        protein_file_cleaned.append(t)\n",
    "\n",
    "    elif \"09\" in b:\n",
    "\n",
    "        b.remove(\"coordinates\")\n",
    "        b.remove(\"docked.pdbqt\")\n",
    "        b.remove(\"1.pdbqt.pdb\")\n",
    "        b.remove(\"combined.pdb\")\n",
    "        b.remove(\"plip\")\n",
    "        b.remove(\"pose\")\n",
    "        b.remove(\"cipro\")\n",
    "        b[2] = b[2].replace(\".pdbqt\",\"\")\n",
    "\n",
    "        t = \"_\".join(b)\n",
    "\n",
    "        protein_file_cleaned.append(t)\n",
    "\n",
    "cipro_binding_sites[\"Coordinates\"] = protein_file_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79841564",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_and_metadata_file_name = cipro[\"Ligand\"].to_list()\n",
    "\n",
    "protein_file_cleaned =[]\n",
    "\n",
    "for i in range(len(cipro)):\n",
    "\n",
    "    b = proteins_and_metadata_file_name[i].split(\"_\")\n",
    "\n",
    "\n",
    "    if \"12\" in b:\n",
    "\n",
    "        b.remove(\"coordinates.pdbqt\")\n",
    "        t = \"_\".join(b)\n",
    "\n",
    "        protein_file_cleaned.append(t)\n",
    "\n",
    "    elif \"09\" in b:\n",
    "\n",
    "        b.remove(\"coordinates\")\n",
    "\n",
    "        b[2] = b[2].replace(\".pdbqt\",\"\")\n",
    "\n",
    "        t = \"_\".join(b)\n",
    "\n",
    "        protein_file_cleaned.append(t)\n",
    "\n",
    "protein_file_cleaned\n",
    "cipro[\"Coordinates\"] = protein_file_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipro_all = pd.merge(cipro,cipro_binding_sites, on = \"Coordinates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipro_all[\"Residue\"] = cipro_all[\"Residue Number\"].astype(str) +\"-\"+ cipro_all[\"Residue Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipro_bs_count = cipro_all[\"Residue\"].value_counts()\n",
    "cipro_bs_count.to_csv(\"cipro_bs_count.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1cf063",
   "metadata": {},
   "source": [
    "# Analysis for Ligands\n",
    "\n",
    "In here, we start to analyze the data we have in hand.\n",
    "\n",
    "INPUT: masterdf.csv\n",
    "\n",
    "OUTPUT: max_ba_df_194.csv and 178_ligands_in_study.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433368ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ligands = np.unique(masterdf[\"Ligand_y\"])\n",
    "\n",
    "max_ba_df = list()\n",
    "\n",
    "for i in unique_ligands:\n",
    "    \n",
    "    df_lig = masterdf[masterdf['Ligand_y'] == i]\n",
    "    ba_lig = np.unique(df_lig[\"BA\"].values)\n",
    "    max_ba_lig = np.min(ba_lig)\n",
    "    df_lig_ba_max = df_lig[df_lig[\"BA\"] == max_ba_lig]\n",
    "    unique_coordinates = np.unique(df_lig_ba_max[\"Coordinates\"].values)\n",
    "    if len(unique_coordinates) > 1:\n",
    "        #print(max_ba_lig, np.unique(df_lig_ba_max[\"Coordinates\"].values))\n",
    "        df_lig_ba_max = df_lig_ba_max[df_lig_ba_max[\"Coordinates\"] == unique_coordinates[0]]\n",
    "        print(max_ba_lig, np.unique(df_lig_ba_max[\"Coordinates\"].values))\n",
    "        \n",
    "    max_ba_df.append(df_lig_ba_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e906a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ba_df = pd.concat(max_ba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_ligands = np.unique(max_ba_df[\"Ligand_y\"])\n",
    "\n",
    "for i in un_ligands:\n",
    "    ligs = max_ba_df[max_ba_df[\"Ligand_y\"] == i]\n",
    "    print(len(np.unique(ligs[\"BA\"].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c027a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ba_df.sort_values(by = \"BA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a994e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using + operator to combine two columns\n",
    "\n",
    "max_ba_df[\"Residue\"] = max_ba_df['Residue Number'].astype(str) +\"-\"+ max_ba_df[\"Residue Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb348f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ba_df[\"Residue\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868788be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ba_df.to_csv(\"max_ba_df_194.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_ids = pd.read_csv(\"Unique_Chembl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ligs = np.unique(masterdf[\"Ligand_y\"])\n",
    "\n",
    "newdf = []\n",
    "\n",
    "for i in unique_ligs:\n",
    "    new = chembl_ids[chembl_ids[\"Molecule.ChEMBL.ID\"] == i]\n",
    "    newdf.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586eb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.to_csv(\"178_ligands_in_study.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d246571",
   "metadata": {},
   "source": [
    "# Calculating Tanimoto score and Tanimoto Heatmap\n",
    "\n",
    "INPUT: 178_ligands_in_study.csv # this file includes SMILES ID's which is used to calculate Tanimoto\n",
    "\n",
    "OUTPUT: Cluster map of Tanimoto scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating tanimoto\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "\n",
    "# show full results\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "# Reading the input CSV file.\n",
    "\n",
    "ligands_df = pd.read_csv(\"178_ligands_in_study.csv\" , index_col=0 )\n",
    "print(ligands_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Creating molecules and storing in an array\n",
    "molecules = []\n",
    "\n",
    "\"\"\"Let's fetch the smiles from the input file and store in molecules array\n",
    "        We have used '_' because we don't want any other column.\n",
    "        If you want to fetch index and any other column, then replace '_' with \n",
    "            index and write column names after a ','.\n",
    "\"\"\"\n",
    "\n",
    "for _, smiles in ligands_df[[ \"SMILES\"]].itertuples():\n",
    "    molecules.append((Chem.MolFromSmiles(smiles)))\n",
    "molecules[:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b217431",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_arrays_df = pd.DataFrame(similarities, columns= ligands_df[\"Molecule.ChEMBL.ID\"], index = ligands_df[\"Molecule.ChEMBL.ID\"])\n",
    "plot = sns.clustermap(similarities_arrays_df, cmap = \"Blues\")\n",
    "#plot.savefig(\"tanimoto_similarities.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b2ff5",
   "metadata": {},
   "source": [
    "# Binding Site Heatmap\n",
    "\n",
    "INPUT: max_ba_df_194.csv\n",
    "\n",
    "OUTPUT: Binding site heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44adb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ba_df_194 = pd.read_csv(\"max_ba_df_194.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da75171",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ba_df_194 = max_ba_df_194[max_ba_df_194[\"Standard.Value\"] > 20]\n",
    "\n",
    "max_ba_df_194[\"Residue\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04597e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_aa_nora = np.unique(max_ba_df_194[\"Residue Number\"].sort_values())\n",
    "\n",
    "unique_ligands = np.unique(max_ba_df_194[\"Ligand_y\"])\n",
    "\n",
    "all_arrays = []\n",
    "\n",
    "for i in unique_ligands:\n",
    "    \n",
    "    ligs = max_ba_df_194[max_ba_df_194[\"Ligand_y\"] == i]\n",
    "    \n",
    "    empty_array = np.zeros(len(binding_aa_nora)) \n",
    "    \n",
    "    for j in range(len(binding_aa_nora)):\n",
    "        \n",
    "        aa = binding_aa_nora[j]\n",
    "        \n",
    "        if aa in ligs[\"Residue Number\"].values:\n",
    "            \n",
    "            \n",
    "            empty_array[j] = 1\n",
    "            \n",
    "    all_arrays.append(empty_array)\n",
    "\n",
    "all_arrays_df = pd.DataFrame(all_arrays, columns= binding_aa_nora, index = unique_ligands)\n",
    "\n",
    "plot = sns.clustermap(all_arrays_df, cmap=\"Blues\", figsize= (20,20))\n",
    "\n",
    "sns.set(font_scale = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182b1c7",
   "metadata": {},
   "source": [
    "# Cluster Analysis for Binding Sites\n",
    "\n",
    "INPUT: all_arrays_df from binding site analysis\n",
    "\n",
    "OUTPUT: cluster_of_binding_sites.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# retrieve clusters using fcluster \n",
    "d = sch.distance.pdist(all_arrays_df)\n",
    "L = sch.linkage(d, method='complete')\n",
    "# 0.2 can be modified to retrieve more stringent or relaxed clusters\n",
    "clusters = sch.fcluster(L, 0.85*d.max(), 'distance')\n",
    "\n",
    "# clusters indicices correspond to incides of original df\n",
    "\n",
    "df_index = []\n",
    "cluster_no = []\n",
    "\n",
    "for i,cluster in enumerate(clusters):\n",
    "    print(all_arrays_df.index[i], cluster)\n",
    "    df_index.append(all_arrays_df.index[i])\n",
    "    cluster_no.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5827eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_binding_sites = pd.DataFrame(list(zip(df_index,cluster_no)), columns= [\"in\",\"mol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_binding_sites.to_csv(\"cluster_of_binding_sites.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a3682",
   "metadata": {},
   "source": [
    "# Cluster Analysis for Tanimoto Scores\n",
    "\n",
    "INPUT: similarities_arrays_df from tanimoto score analysis\n",
    "\n",
    "OUTPUT: cluster_of_similarity_scores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# retrieve clusters using fcluster \n",
    "d = sch.distance.pdist(similarities_arrays_df)\n",
    "L = sch.linkage(d, method='complete')\n",
    "# 0.2 can be modified to retrieve more stringent or relaxed clusters\n",
    "clusters = sch.fcluster(L, 0.5*d.max(), 'distance')\n",
    "\n",
    "# clusters indicices correspond to incides of original df\n",
    "\n",
    "df_index = []\n",
    "cluster_no = []\n",
    "\n",
    "for i,cluster in enumerate(clusters):\n",
    "    print(all_arrays_df.index[i], cluster)\n",
    "    df_index.append(all_arrays_df.index[i])\n",
    "    cluster_no.append(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_similarity_scores = pd.DataFrame(list(zip(df_index,cluster_no)), columns= [\"in\",\"mol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb11c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_similarity_scores.to_csv(\"cluster_of_similarity_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec150c29",
   "metadata": {},
   "source": [
    "# Generating one file including also information of clusters\n",
    "\n",
    "INPUT: 178_ligands_in_study.csv, clusterofsimilarityscores, clusterofbindingsites\n",
    "\n",
    "OUTPUT: final_data_with_clusters.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"178_ligands_in_study.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06540bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterofsimilarityscores.columns = [\"Index\",\"Molecule.ChEMBL.ID\", \"Tanimoto Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0fd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterofbindingsites.columns = [\"Index\",\"Molecule.ChEMBL.ID\", \"Binding Site Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf = pd.merge(metadata,clusterofsimilarityscores, on=\"Molecule.ChEMBL.ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf = pd.merge(masterdf,clusterofbindingsites, on=\"Molecule.ChEMBL.ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759f75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tanimoto_cluster = masterdf[\"Tanimoto Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_site_cluster = masterdf[\"Binding Site Cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df000e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf.to_csv(\"final_data_with_clusters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31818c7a",
   "metadata": {},
   "source": [
    "# Confusion Matrix for Tanimoto vs Binding Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea136e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(tanimoto_cluster, binding_site_cluster)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2fb01",
   "metadata": {},
   "source": [
    "# Generating RMSD, RMSF plots\n",
    "\n",
    "\n",
    "INPUT: DCD and PDB files under Important_Files/DCD_Files # DCD files are obtained by VMD and PDB files are the ones used as an input to MD.\n",
    "\n",
    "OUTPUT: Plots of RMSD and RMSF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062326fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = parseDCD(\"Important_Files/DCD_Files/12_08_2021_10_skipped.dcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure1 = parsePDB(\"Important_Files/DCD_Files/12_08_step5_input.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f3d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure1 = structure1.select(\"protein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.setAtoms(structure1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = file1[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb852",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.superpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.setAtoms(structure1.calpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0ee804",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsd_file1 = file1.getRMSDs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsf_file1 = file1.getRMSFs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fdf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "ax.plot(rmsd_file1,color = \"black\")\n",
    "ax.set_xlabel(\"Time (ns)\", fontsize = 15)\n",
    "ax.set_ylabel(\"RMSD ()\", fontsize = 15)\n",
    "ax.set_title(\"RMSD over the simulation 08_12_2021\", fontsize = 18)\n",
    "ax.set_xticks([0,200,400,600,800,1000])\n",
    "ax.set_xticklabels(['0','20','40','60',\"80\",\"100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "ax.plot(rmsf_file1,color = \"black\")\n",
    "ax.set_xlabel(\"Residue  Carbons\", fontsize = 15)\n",
    "ax.set_ylabel(\"RMSF ()\", fontsize = 15)\n",
    "ax.set_title(\"RMSF over the simulation 08_12_2021\", fontsize =18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = parseDCD(\"Important_Files/DCD_Files/21_09_2021.dcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6190db",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure2 = parsePDB(\"Important_Files/DCD_Files/09_21_step5_input.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure2 = structure2.select(\"protein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.setAtoms(structure2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.setAtoms(structure2.calpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = file2[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6561924",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2.superpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80567ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsd_file2 = file2.getRMSDs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b11a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsf_file2 = file2.getRMSFs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245776a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "ax.plot(rmsd_file2,color = \"black\")\n",
    "ax.set_xlabel(\"Time (ns)\", fontsize = 15)\n",
    "ax.set_ylabel(\"RMSD ()\", fontsize = 15)\n",
    "ax.set_title(\"RMSD over the simulation 09_21_2021\", fontsize = 18)\n",
    "ax.set_xticks([0,200,400,600,800,1000])\n",
    "ax.set_xticklabels(['0','20','40','60',\"80\",\"100\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(rmsf_file2, color = \"black\")\n",
    "plt.xlabel(\"Residue  Carbons\",fontsize = 15)\n",
    "plt.ylabel(\"RMSF ()\",fontsize = 15)\n",
    "plt.title(\"RMSF over the simulation 09_21_2021\",fontsize = 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
